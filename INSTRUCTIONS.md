# Instructions
Even though HEBench supports multiple benchmarks in a single backend, for easy of review and processing, only a single benchmark is allowed in a submission. If submitter wants to submit multiple benchmarks, then, a submission per benchmark is required.

There is a single main repository per submission.

Submission repo must follow the format below.

```
+ dataset
+ docs
+ external
+ notes
+ reports
+ source
+ versions
benchmark_config.yaml
id.yaml
LICENSE
README.md
report.yaml
system_info.yaml
```

Items marked with `+` are directories. The rest are files.

## Directories

All directories must exist, regardless of whether they are empty or not. To keep an empty directory in Git, add an empty file named `deleteme`.

### dataset
If any dataset is required to perform the benchmark, it must be included in this directory.

One of the following must be included if a custom dataset is required to execute the benchmark:

- Full dataset, prepared and directly compatible for use with HEBench frontend (it must use Git Large File System, or LFS).
- Scripts to obtain and prepare the dataset for use with HEBench frontend.
- Detailed and easy-to-follow instructions to obtain and prepare the dataset for use with HEBench frontend.

If a dataset is needed, it must be mentioned specifically in the top level `README` in this repo.

### docs
Contains any extra documentation for the submission.

### external
Contains any extra files that do not belong in any other directories, but are required to compile and run the benchmarks. These include, but are not limited to proprietary binaries for libraries, drivers, or firmware.

### notes
Contains optional text files with notes and explanations for each benchmark. Submitters can use these notes to show the algorithm used to solve the workload, or highlight any relevant information. Files contained in this directory will be referenced to by the root file `reports.yaml`.

These notes should be simple and concise. If more in-depth information and documentation is required, submitters can use the `docs` directory.

### reports
Contains the report CSV file for the submitted benchmark as generated by HEBench Frontend's Test Harness when executed with the benchmark configuration file provided at the root of this repo.

The report contained herein has the results obtained by submitter using the information in this submission. These results will be used to display the published submission.

### source
Contains the code and build system necessary to build the backend library to benchmark the submission. This may be used to replicate the results during auditing.

Results replicated using this code will be compared to those submitted under `reports`.

### versions
Version files for HEBench **API Bridge** and **Frontend** used to compile the backend and obtain the results under `reports`.

Files:

```
API_BRIDGE.version
FRONTEND.version
```

These are copies of the files named `VERSION` in the root directory of the API Bridge and Frontend repos (of the specified version) respectively.

## Files

### benchmark_config.yaml
*Submitter provided*

This is the configuration file used with Frontend's Test Harness to run the benchmarks for which the submitted report was generated. See [HEBench Test Harness documentation](https://hebench.github.io/frontend/test_harness_usage_guide.html) for information on generating and using benchmark configuration files. This is used to reproduce results.

### id.yaml
*Auto-generated*

YAML file containing ID of submission and submitter name. This must not be modified.

### LICENSE
*Auto-generated*

License file containing the license governing the submission.

### `README.md`
*Submitter provided*

"Readme" file containing instructions on how to build, run the benchmark, and replicate the submitted results. The format is not enforced, but see the included file for an example of its contents. If, during audit, instructions cannot be followed properly to build and run the benchmarks to reproduce results, the submission may be returned with requests for modification.

Submitters can provide further documentation in the `docs` directory to better organize the top `README`.

### report.yaml
*Submitter provided*

YAML file listing details regarding benchmark along with report-specific information. The format of the file is as below.
```yaml
filename: "relative/path/to/first/report.csv"
software: "<software>"
software_version: "<software_version>"
cpu_threads: <number_of_threads>
accelerator: "<accelerator_name>"
accelerator_tdp: <accelerator_tdp_in_W>
accelerator_quantity: <number_of_accelerators_used>
notes: "<extra_notes>"
```

For the benchmark the following should appear in this file:

- **filename**: `string` - relative path to the report file contained in the submission.
- **software**: `string` - software library used for HE operations. Must be `null` if no named software library was used.
- **version**: `string` - version of the software library listed under `software`, or `null` if no version or library.
- **cpu_threads**: `integer` - number of CPU threads used during the actual operation (API Bridge `operate()`). Must be `1` or greater.
- **accelerator**: `string` - name of the accelerator used for HE operations. Must be `null` if no accelerator was used.
- **accelerator_tdp**: `integer` - TDP of accelerator in Watts. Must be `null` if not known or no accelerator.
- **accelerator_quantity**: `integer` - Number of accelerators used for the benchmark. Must be `0` or greater.
- **notes**: `string` - contains either a 256-characters note on the benchmark, a relative path to text file containing the note inside `notes` directory, or `null` if none. This can be used by submitters to highlight notes on the benchmark such as algorithm used for the operation or other specifics. These notes will be displayed with the submission.

### system_info.yaml
*Submitter provided*

YAML file containing the system information of the machine used to run the benchmark. If multiple systems were used, this must be the information of the system where the core HE operation was executed (usually, the API Bridge `operate()` function).

This file can be generated using provided scripts, or manually filled to match the provided example template.

